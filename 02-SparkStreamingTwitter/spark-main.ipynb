{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a525733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row #Converte RDDs em objetos do tipo Row\n",
    "from pyspark.sql.functions import col, isnan, when, count # Encontra a contagem para valores None, Null, Nan, etc.\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Módulos usados\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from operator import add\n",
    "import requests_oauthlib\n",
    "from time import gmtime, strftime\n",
    "import requests\n",
    "import time\n",
    "import string\n",
    "import ast\n",
    "import json\n",
    "#import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a3bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of 1 second\n",
    "ssc = StreamingContext(sc, 1)\n",
    "\n",
    "# Create a DStream that will connect to hostname:port, like localhost:9999\n",
    "lines = ssc.socketTextStream(\"127.0.0.1\", 5554)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1a372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista vazia para os resultados\n",
    "resultados = []\n",
    "\n",
    "# Essa função classifica os tweets, aplicando as features do modelo criado anteriormente\n",
    "def classifica_tweet(tweet):\n",
    "    return(tweet, 'ok')\n",
    "\n",
    "\n",
    "# Essa função retorna o texto do Twitter\n",
    "def get_tweet_text(rdd):\n",
    "    for line in rdd:\n",
    "        tweet = line.strip()\n",
    "        translator = str.maketrans({key: None for key in string.punctuation})\n",
    "        tweet = tweet.translate(translator)\n",
    "        tweet = tweet.split(' ')\n",
    "        tweet_lower = []\n",
    "        for word in tweet:\n",
    "            tweet_lower.append(word.lower())\n",
    "    return(classifica_tweet(tweet_lower))\n",
    "\n",
    "\n",
    "# Essa função salva o resultado dos batches de Tweets junto com o timestamp\n",
    "def output_rdd(rdd):\n",
    "    global resultados\n",
    "    pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
    "    counts = pairs.reduceByKey(add)\n",
    "    output = []\n",
    "    for count in counts.collect():\n",
    "        output.append(count)\n",
    "    result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "    resultados.append(result)\n",
    "    print(result)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bece5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saida(rdd):\n",
    "    global resultados\n",
    "    # Count each word in each batch\n",
    "    #pairs = words.map(lambda word: (word, 1))\n",
    "    #wordCounts = pairs.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "    #output = []\n",
    "    #for count in wordCounts.collect():\n",
    "    #    word = limparTexto(count[0])\n",
    "    #    if word != '':\n",
    "    #        if count[0] not in stop_words:\n",
    "    #            output.append(count)\n",
    "\n",
    "    #resultados = []\n",
    "    #result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "    resultados.append(rdd)\n",
    "    print(resultados)\n",
    "    \n",
    "    return(rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "por = stopwords.words('portuguese')\n",
    "eng = stopwords.words('english')\n",
    "spa = stopwords.words('spanish')\n",
    "\n",
    "stop_words = por + eng + spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ce46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "#words_trans = lines.map(lambda x: limparTexto(x)).map(lambda x: removerStopwords(x))\n",
    "\n",
    "# Split each line into words\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# Count each word in each batch\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "\n",
    "#resultados.append(wordCounts)\n",
    "\n",
    "#coord_stream = lines.map(lambda line: ast.literal_eval(line))\n",
    "# A função foreachRDD() aplica uma função a cada RDD to streaming de dados\n",
    "#coord_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))\n",
    "\n",
    "#wordCounts.foreachRDD(lambda t, rdd: output_rdd(rdd))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the first ten elements of each RDD generated in this DStream to the console\n",
    "wordCounts.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f889e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:29\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:30\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:31\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:32\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:33\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:34\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:35\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:36\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:37\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:38\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:39\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:41\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:42\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:43\n",
      "-------------------------------------------\n",
      "('@alexriesart', 1)\n",
      "('Due', 1)\n",
      "('do', 1)\n",
      "('in', 2)\n",
      "('even', 1)\n",
      "('go', 1)\n",
      "('crazyshit', 1)\n",
      "('experienceRT', 1)\n",
      "(\"Today's\", 1)\n",
      "('of', 4)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:44\n",
      "-------------------------------------------\n",
      "('got', 1)\n",
      "('stuck', 1)\n",
      "('@walterkirn', 1)\n",
      "('both', 3)\n",
      "('of', 16)\n",
      "('them', 1)\n",
      "('', 21)\n",
      "('heavily', 1)\n",
      "('in', 14)\n",
      "('effort.\"', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:45\n",
      "-------------------------------------------\n",
      "('General', 1)\n",
      "('in', 20)\n",
      "('Ukraine', 9)\n",
      "('kein', 1)\n",
      "('gegen', 1)\n",
      "('sure,', 1)\n",
      "('@ZelenskyyUa:', 1)\n",
      "('leadership', 1)\n",
      "('l’amara', 1)\n",
      "('dell’agire', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:46\n",
      "-------------------------------------------\n",
      "('President', 2)\n",
      "('Volodymyr', 1)\n",
      "('territorio', 1)\n",
      "('los', 1)\n",
      "('respuesta', 1)\n",
      "('Rusia', 1)\n",
      "('y', 2)\n",
      "('n…@JebraFaushay', 1)\n",
      "('They', 1)\n",
      "('would', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:47\n",
      "-------------------------------------------\n",
      "('das', 1)\n",
      "('ich', 1)\n",
      "('SLM', 1)\n",
      "('kartını', 1)\n",
      "('daha', 1)\n",
      "('telaslı', 1)\n",
      "('galiba.', 1)\n",
      "('guzel', 1)\n",
      "('simps,', 1)\n",
      "('&amp;', 5)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:48\n",
      "-------------------------------------------\n",
      "('Enjoy:', 1)\n",
      "('Margarita', 2)\n",
      "('of', 10)\n",
      "('in', 18)\n",
      "('Ukraine', 12)\n",
      "('needs', 3)\n",
      "('', 22)\n",
      "('scemo@taylor_jona', 1)\n",
      "('and,hence,', 1)\n",
      "('birds', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:49\n",
      "-------------------------------------------\n",
      "('Ukrainians', 1)\n",
      "('@ANI:', 1)\n",
      "('Russian', 2)\n",
      "('President', 2)\n",
      "('bridge', 3)\n",
      "('blast', 1)\n",
      "('an', 4)\n",
      "('of', 15)\n",
      "('@Praskozorje1', 1)\n",
      "('have', 3)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:50\n",
      "-------------------------------------------\n",
      "('in', 13)\n",
      "('&amp;', 2)\n",
      "('EU', 1)\n",
      "('especially', 2)\n",
      "('China’s', 1)\n",
      "('gradually', 1)\n",
      "('Ukraine', 10)\n",
      "('other', 3)\n",
      "('country', 1)\n",
      "('willing', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:51\n",
      "-------------------------------------------\n",
      "('even', 1)\n",
      "('@bpolitics:', 1)\n",
      "('pressure', 1)\n",
      "('in', 16)\n",
      "('Ukraine', 8)\n",
      "('https://t.co/dykCNNoYfORT', 1)\n",
      "('Russian', 6)\n",
      "('are', 5)\n",
      "('bridge”.', 1)\n",
      "('They', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:52\n",
      "-------------------------------------------\n",
      "('video,', 1)\n",
      "('filmed', 1)\n",
      "('during', 2)\n",
      "('Ukraine', 10)\n",
      "('in', 16)\n",
      "('It', 3)\n",
      "('sho…@newsmax', 1)\n",
      "('Will', 3)\n",
      "('set', 1)\n",
      "('like', 3)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:53\n",
      "-------------------------------------------\n",
      "('Its', 1)\n",
      "('watching', 1)\n",
      "('balance', 1)\n",
      "('\"Russia', 1)\n",
      "('the…RT', 1)\n",
      "('momento', 1)\n",
      "('vai', 2)\n",
      "('do', 5)\n",
      "('passado', 1)\n",
      "('migrantów', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:54\n",
      "-------------------------------------------\n",
      "('https://t.co/KGO8EC2OsKRT', 1)\n",
      "('24', 1)\n",
      "('like', 2)\n",
      "('have', 7)\n",
      "('already', 1)\n",
      "('Ukraine', 5)\n",
      "('of', 25)\n",
      "('@RedAMLOmorena:', 1)\n",
      "('Trump', 1)\n",
      "('paz.', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:55\n",
      "-------------------------------------------\n",
      "('Rusia', 1)\n",
      "('no', 2)\n",
      "('siamo', 1)\n",
      "('in', 20)\n",
      "('Ukraine', 9)\n",
      "('may', 1)\n",
      "('have', 3)\n",
      "('@DmytroKuleba:', 2)\n",
      "('nonsense', 1)\n",
      "('must', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:56\n",
      "-------------------------------------------\n",
      "('in', 14)\n",
      "('Ukraine', 9)\n",
      "('strategic', 3)\n",
      "('an', 3)\n",
      "('🧵', 2)\n",
      "('', 19)\n",
      "('.endf', 1)\n",
      "('edf', 1)\n",
      "('have', 2)\n",
      "('both', 2)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:57\n",
      "-------------------------------------------\n",
      "('Der', 1)\n",
      "('grüne', 1)\n",
      "('Mist', 1)\n",
      "('ist', 2)\n",
      "('in', 15)\n",
      "('respuesta', 1)\n",
      "('bombardear', 1)\n",
      "('Ucrania.', 1)\n",
      "('quien', 1)\n",
      "('lo', 1)\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2022-10-10 11:32:58\n",
      "-------------------------------------------\n",
      "('And', 2)\n",
      "('Ukrainians', 2)\n",
      "('are', 9)\n",
      "('bombardment', 1)\n",
      "('terrifying.', 1)\n",
      "('of', 18)\n",
      "('angry.', 1)\n",
      "('ein', 1)\n",
      "('https://t.co/ghSUmL4JYDRT', 1)\n",
      "('@AFP:', 1)\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()             # Start the computation\n",
    "ssc.awaitTerminationOrTimeout(120)  # Wait for the computation to terminate\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e7ff2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.streaming.dstream.TransformedDStream"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = wordCounts.map(lambda line: ast.literal_eval(line))\n",
    "type(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362c4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função classifica os tweets, aplicando as features do modelo criado anteriormente\n",
    "def classifica_tweet(tweet):\n",
    "    return(tweet, 'ok')\n",
    "\n",
    "# Essa função retorna o texto do Twitter\n",
    "def get_tweet_text(rdd):\n",
    "    for line in rdd:\n",
    "        tweet = line.strip()\n",
    "        tweet_lower = []\n",
    "        for word in tweet:\n",
    "            tweet_lower.append(word.lower())\n",
    "    return(classifica_tweet(tweet_lower))\n",
    "\n",
    "# Essa função salva o resultado dos batches de Tweets junto com o timestamp\n",
    "def output_rdd(rdd):\n",
    "    global resultados\n",
    "    pairs = rdd.map(lambda x: (get_tweet_text(x)[0],1))\n",
    "    counts = pairs.reduceByKey(add)\n",
    "    output = []\n",
    "    for count in counts.collect():\n",
    "        output.append(count)\n",
    "    result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "    resultados.append(result)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f4e036",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.streaming.api.python.PythonDStream.callForeachRDD.\n: java.lang.IllegalStateException: Adding new inputs, transformations, and output operations after stopping a context is not supported\r\n\tat org.apache.spark.streaming.dstream.DStream.validateAtInit(DStream.scala:230)\r\n\tat org.apache.spark.streaming.dstream.DStream.<init>(DStream.scala:67)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.<init>(ForEachDStream.scala:39)\r\n\tat org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:655)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$3(DStream.scala:640)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:763)\r\n\tat org.apache.spark.streaming.StreamingContext.withScope(StreamingContext.scala:264)\r\n\tat org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:640)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.callForeachRDD(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream.callForeachRDD(PythonDStream.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22120/3849554912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# A função foreachRDD() aplica uma função a cada RDD to streaming de dados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwordCounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforeachRDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput_rdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Tools\\Spark\\python\\pyspark\\streaming\\dstream.py\u001b[0m in \u001b[0;36mforeachRDD\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mjfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonDStream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallForeachRDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\Spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\Spark\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\Spark\\python\\lib\\py4j-0.10.9-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.streaming.api.python.PythonDStream.callForeachRDD.\n: java.lang.IllegalStateException: Adding new inputs, transformations, and output operations after stopping a context is not supported\r\n\tat org.apache.spark.streaming.dstream.DStream.validateAtInit(DStream.scala:230)\r\n\tat org.apache.spark.streaming.dstream.DStream.<init>(DStream.scala:67)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.<init>(ForEachDStream.scala:39)\r\n\tat org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:655)\r\n\tat org.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$3(DStream.scala:640)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:763)\r\n\tat org.apache.spark.streaming.StreamingContext.withScope(StreamingContext.scala:264)\r\n\tat org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:640)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.callForeachRDD(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream.callForeachRDD(PythonDStream.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n"
     ]
    }
   ],
   "source": [
    "# A função foreachRDD() aplica uma função a cada RDD to streaming de dados\n",
    "wordCounts.foreachRDD(lambda t, rdd: output_rdd(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6776d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removerStopwords(texto):\n",
    "    por = stopwords.words('portuguese')\n",
    "    eng = stopwords.words('english')\n",
    "    spa = stopwords.words('spanish')\n",
    "\n",
    "    stop_words = por + eng + spa\n",
    "    \n",
    "    texto = ' '.join(palavra for palavra in texto.split(' ') if palavra not in stop_words)\n",
    "    return texto\n",
    "\n",
    "def limparTexto(texto):\n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    texto = emoji_pattern.sub(r'', texto) # no emoji\n",
    "    \n",
    "    # Remove non-english chars: chinese, arabic, korean, etc...\n",
    "    nonenglish_pattern = re.compile(u'[^\\u0000-\\u05C0\\u2100-\\u214F]+', flags=re.UNICODE)\n",
    "    texto = nonenglish_pattern.sub(r'', texto)\n",
    "    \n",
    "    #Vamos transformar o texto em lowercase, remover textos entre colchetes, links, pontuações e palavras que contenham números.\n",
    "    texto = str(texto).lower()\n",
    "    texto = re.sub('\\[.*?\\]', '', texto) #Removendo textos entre colchetes\n",
    "    texto = re.sub('<.*?>+', '', texto)  # Remove textos entre <>\n",
    "    texto = re.sub('https?://\\S+|www\\.\\S+', '', texto) #Removendo links\n",
    "    texto = re.sub('[@#]\\S+', '', texto) #Removendo arrobas e hashtags\n",
    "    texto = re.sub('\\w*\\d\\w*', '', texto) #Remove palavras contendo dígitos no meio.\n",
    "        \n",
    "    texto = re.sub(r'[%@#\\t\\n\\r]+', '', texto) #Remove caracteres especiais\n",
    "    texto = re.sub(r'[ ]+', ' ', texto) #Remove mais do que um espaço em branco\n",
    "    \n",
    "    return (texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4078b0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc51d86",
   "metadata": {},
   "source": [
    "Links: \n",
    "\n",
    "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#programming-model\n",
    "\n",
    "https://github.com/syalanuj/youtube/blob/main/spark_streaming_with_python_in_12_minutes/spark_st_run.ipynb\n",
    "\n",
    "https://github.com/Krupique/cursos-datascience-conteudo/blob/main/DSA_DS-02-BigData%20Analytics%20com%20Python%20e%20Spark/05%20-%20Introducao-SparkStreaming.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c83125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['É necessário muita ação',\n",
       " 'I plan nothing on my weekend ！#cute #可爱 #萌 #cat https://t.co/JNbftLiVOM',\n",
       " '@PAVGOD: Whenever someone asks if Pavlov is a cuddle dog,          I try to explain that this is his reaction 😂 https://t.co/KGrI4pHEXV',\n",
       " 'Cat feed cat https://t.co/1Avv8qhT4J 🗣️\"Tenim el deure de complir amb el mandat del 52 %           davançar cap a la independència']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [\n",
    "    'É necessário muita ação',\n",
    "    'I plan nothing on my weekend ！#cute #可爱 #萌 #cat https://t.co/JNbftLiVOM',\n",
    "         '@PAVGOD: Whenever someone asks if Pavlov is a cuddle dog, \\\n",
    "         I try to explain that this is his reaction 😂 https://t.co/KGrI4pHEXV',\n",
    "         'Cat feed cat https://t.co/1Avv8qhT4J 🗣️\"Tenim el deure de complir amb el mandat del 52 %  \\\n",
    "         davançar cap a la independència'\n",
    "        ]\n",
    "\n",
    "rdd = sc.parallelize(lista)\n",
    "\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d137290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa função salva o resultado dos batches de Tweets junto com o timestamp\n",
    "def output_rdd(rdd):\n",
    "    global resultados\n",
    "    pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
    "    counts = pairs.reduceByKey(add)\n",
    "    output = []\n",
    "    for count in counts.collect():\n",
    "        output.append(count)\n",
    "    result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "    resultados.append(result)\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fc55b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = rdd.flatMap(lambda line: line.split(' '))\n",
    "\n",
    "filt = rdd1.filter(lambda line: removerStopwords(line))\n",
    "\n",
    "pairs = rdd1.map(lambda x: (x.lower(), 1))\n",
    "\n",
    "counts = pairs.reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16a696fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 2),\n",
       " ('#可爱', 1),\n",
       " ('', 19),\n",
       " ('😂', 1),\n",
       " ('https://t.co/kgri4phexv', 1),\n",
       " ('cat', 2),\n",
       " ('feed', 1),\n",
       " ('el', 2),\n",
       " ('deure', 1),\n",
       " ('cap', 1),\n",
       " ('nothing', 1),\n",
       " ('weekend', 1),\n",
       " ('！#cute', 1),\n",
       " ('@pavgod:', 1),\n",
       " ('whenever', 1),\n",
       " ('someone', 1),\n",
       " ('a', 2),\n",
       " ('dog,', 1),\n",
       " ('to', 1),\n",
       " ('that', 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82f91730",
   "metadata": {},
   "outputs": [],
   "source": [
    "por = stopwords.words('portuguese')\n",
    "eng = stopwords.words('english')\n",
    "spa = stopwords.words('spanish')\n",
    "\n",
    "stop_words = por + eng + spa\n",
    "\n",
    "output = []\n",
    "for count in counts.collect():\n",
    "    \n",
    "    word = limparTexto(count[0])\n",
    "    if word != '':\n",
    "        if count[0] not in stop_words:\n",
    "            output.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1d43ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10:47:51', [('cat', 2), ('feed', 1), ('deure', 1), ('cap', 1), ('nothing', 1), ('weekend', 1), ('whenever', 1), ('someone', 1), ('dog,', 1), ('reaction', 1), ('amb', 1), ('davançar', 1), ('plan', 1), ('pavlov', 1), ('try', 1), ('🗣️\"tenim', 1), ('complir', 1), ('independència', 1), ('necessário', 1), ('muita', 1), ('ação', 1), ('asks', 1), ('cuddle', 1), ('explain', 1), ('mandat', 1)]]\n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "resultados.append(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd3 = rdd.map(lambda x: limparTexto(x)).map(lambda x: removerStopwords(x))\n",
    "\n",
    "rdd3.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98965fff",
   "metadata": {},
   "source": [
    "## Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935bc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "from collections import namedtuple\n",
    "\n",
    "# Can only run this once. restart your kernel for any errors.\n",
    "\n",
    "ssc = StreamingContext(sc, 10 )\n",
    "sqlContext = SQLContext(sc)\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5554)\n",
    "\n",
    "lines = socket_stream.window( 100 )\n",
    "\n",
    "fields = (\"text\")\n",
    "\n",
    "# Use Parenthesis for multiple lines or use \\.\n",
    "Tweet = namedtuple( 'Tweet', fields )\n",
    "( lines.flatMap( lambda text: text.split( \" \" ) ) \n",
    "     #.filter( lambda word: word.lower().startswith(\"http\") )  \n",
    "     .map( lambda word: ( word.lower(), 1 ) ) \n",
    "     .reduceByKey( lambda a, b: a + b ) \n",
    "     .map( lambda rec: Tweet( rec[0], rec[1] ) ) \n",
    "     .foreachRDD( lambda rdd: rdd.toDF().sort( desc(\"count\") ) \n",
    "     .limit(100).registerTempTable(\"tweets\") ) ) # Registers to a table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca5573",
   "metadata": {},
   "source": [
    "## Now run TweetListener.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f68aa",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f106b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Only works for Jupyter Notebooks!\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59079a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95493ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = sqlContext.sql( 'Select * from tweets' )\n",
    "df = tweets.toPandas()\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
